# 生成式预训练模型
2022年可能是大模型商业化的元年，随着以ChatGPT为代表的LLM的爆火，沉寂多年的NLP再次迎来了投资和研发的热潮，各类AIGC软件如雨后春笋般涌出。  
想法一：  
GPT技术大致分为三步：1、使用大量无标注的语料进行机器学习（被叫做大模型的原因）； 2、使用一定规模有标注的优质语料进行强化学习； 3、基于人类反馈的强化学习（ChatGPT使用专门模型代替这步）  
因为训练的数据量足够大，后续只需对大模型进行微调即可满足各类需求。类比计算机的发展，是否会出现只提供大模型并且不对大模型进行强化学习微调的公司，就像`通用计算机`或者`操作系统`的出现？  
想法二：  
由中文GPT所想，怎么提高模型训练数据量？是否可能出现各互联网企业将数据脱敏或加密后公开给各方使用，一起维护同一个`“巨大的”大模型`，类似`开源社区`的感觉？会否用到`隐私计算`？  
想法三：  
目前成熟的大模型基本上类似于ChatGPT，以文字作为输入和输出，但也在发展图片、视频等`多模态输入`，后续应该会出现`多模态输出`。假如支持以`二进制机器码`输出，那么就可能被用于`可穿戴设备`。如果出现这种情况，因为大模型所需的算力要求很高，该可穿戴设备使用的模型是应该`轻量化`甚至“刚刚好”，还是应该维持大模型的规模，把运算放至`云端`？